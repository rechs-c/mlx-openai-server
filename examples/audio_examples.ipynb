{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Audio Processing with MLX Server\n",
        "\n",
        "This notebook demonstrates how to process audio files using the MLX Server with OpenAI-compatible API.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What You'll Learn\n",
        "\n",
        "- Connect to MLX Server\n",
        "- Load and encode audio files for processing\n",
        "- Send audio to the model for analysis\n",
        "- Get text descriptions of audio content\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- MLX Server running on localhost:8000\n",
        "- Audio file in the `audios/` directory\n",
        "- OpenAI Python library installed\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Setup and Connection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Connected to MLX Server\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "from openai import OpenAI\n",
        "import base64\n",
        "import os\n",
        "\n",
        "# Initialize OpenAI client to connect to MLX Server\n",
        "# The MLX Server runs locally and provides OpenAI-compatible endpoints\n",
        "client = OpenAI(\n",
        "    base_url=\"http://localhost:8000/v1\",  # MLX Server address\n",
        "    api_key=\"fake-api-key\",               # Any string works for local server\n",
        ")\n",
        "\n",
        "print(\"âœ… Connected to MLX Server\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Audio File Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Loaded audio file: audios/audio.wav\n",
            "   File size: 372698 bytes\n",
            "   Encoded size: 496932 characters\n"
          ]
        }
      ],
      "source": [
        "def load_audio_file(audio_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Load an audio file and encode it as base64 for API transmission.\n",
        "    \n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file\n",
        "        \n",
        "    Returns:\n",
        "        str: Base64 encoded audio data\n",
        "    \"\"\"\n",
        "    if not os.path.exists(audio_path):\n",
        "        raise FileNotFoundError(f\"Audio file not found: {audio_path}\")\n",
        "    \n",
        "    with open(audio_path, \"rb\") as audio_file:\n",
        "        audio_data = audio_file.read()\n",
        "        encoded_audio = base64.b64encode(audio_data).decode('utf-8')\n",
        "        \n",
        "    print(f\"âœ… Loaded audio file: {audio_path}\")\n",
        "    print(f\"   File size: {len(audio_data)} bytes\")\n",
        "    print(f\"   Encoded size: {len(encoded_audio)} characters\")\n",
        "    \n",
        "    return encoded_audio\n",
        "\n",
        "# Load the sample audio file\n",
        "audio_path = \"audios/audio.wav\"\n",
        "audio_base64 = load_audio_file(audio_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Audio Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽµ Audio Analysis Result:\n",
            "   Dogs are sitting by the door.\n"
          ]
        }
      ],
      "source": [
        "def analyze_audio(audio_base64: str, prompt: str = \"Describe what you hear in this audio.\") -> str:\n",
        "    \"\"\"\n",
        "    Send audio to MLX Server for analysis.\n",
        "    \n",
        "    Args:\n",
        "        audio_base64 (str): Base64 encoded audio data\n",
        "        prompt (str): Text prompt for the model\n",
        "        \n",
        "    Returns:\n",
        "        str: Model's response\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"local-multimodal\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\", \n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"input_audio\",\n",
        "                            \"input_audio\": {\n",
        "                                \"data\": audio_base64,\n",
        "                                \"format\": \"wav\"\n",
        "                            }\n",
        "                        },\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": prompt\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            max_tokens=1024\n",
        "        )\n",
        "        \n",
        "        return response.choices[0].message.content\n",
        "        \n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing audio: {str(e)}\"\n",
        "\n",
        "# Analyze the audio with a descriptive prompt\n",
        "result = analyze_audio(audio_base64, \"Describe the audio in detail.\")\n",
        "print(\"ðŸŽµ Audio Analysis Result:\")\n",
        "print(f\"   {result}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated the audio processing capabilities of the MLX Server using OpenAI-compatible API endpoints. Key highlights include:\n",
        "\n",
        "- **Audio Input Support**: Successfully processed audio files by encoding them as base64 and sending them through the `input_audio` message type\n",
        "- **Multimodal Integration**: Combined audio input with text prompts to create rich, context-aware responses\n",
        "- **OpenAI Compatibility**: Leveraged familiar OpenAI API patterns for seamless integration with existing workflows\n",
        "- **Error Handling**: Implemented proper error handling for robust audio processing\n",
        "\n",
        "The MLX Server's audio processing capabilities enable powerful applications such as:\n",
        "- Audio transcription and analysis\n",
        "- Voice-controlled interfaces\n",
        "- Audio content summarization\n",
        "- Accessibility features for audio-based content\n",
        "\n",
        "This foundation opens up numerous possibilities for building audio-enabled AI applications with the performance benefits of MLX on Apple Silicon.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "testing",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
